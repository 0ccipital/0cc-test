# Ollama Context Tree Chat ğŸŒ³

Entirely generated by claude-sonnet-4-20250514 on 20250720 on beta.lmarena.ai

A CLI tool for branching conversations with Ollama models. Avoid context pollution by creating conversation trees where you can navigate between different discussion paths.

## Installation

```bash
git clone https://github.com/yourusername/ollama-context-tree-chat.git
cd ollama-context-tree-chat
uv sync
```

## Requirements

- Python 3.8+
- [Ollama](https://ollama.ai) running locally
- At least one Ollama model installed

## Usage

```bash
# Start Ollama
ollama serve

# Run the tool
uv run run.py
```

## Example

```
[new] You: How do I optimize Python code?

ğŸ¤– Assistant: There are several approaches...

[1 (1)] You: What about memory optimization?

ğŸ¤– Assistant: For memory optimization...

[2 (1.1)] You: /goto 1

[1 (1)] You: What about performance instead?

ğŸ¤– Assistant: For performance optimization...

[3 (1.2)] You: /states

ğŸŒ³ Conversation Tree:
1 (1): How do I optimize Python code?
â”œâ”€â”€ 2 (1.1): What about memory optimization?
â””â”€â”€ 3 (1.2): What about performance instead? â† current
```

## Key Commands

- `/goto <id>` - Navigate to any state (e.g., `/goto 2` or `/goto 1.1`)
- `/states` - Show conversation tree
- `/tag <text>` - Tag current state (e.g., `/tag good solution`)
- `/save [name]` - Save conversation
- `/load` - Load conversation
- `/help` - Show all commands

## Why Use This?

When an LLM makes a mistake or you want to try a different approach, traditional chats keep that "bad" context. This tool lets you branch conversations and navigate cleanly between different paths without context pollution.